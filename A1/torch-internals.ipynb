{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All about strides:\n",
    "[PyTorch internals](http://blog.ezyang.com/2019/05/pytorch-internals/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15]],\n",
       "\n",
       "        [[16, 17, 18, 19],\n",
       "         [20, 21, 22, 23],\n",
       "         [24, 25, 26, 27],\n",
       "         [28, 29, 30, 31]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(32).view(2,4,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [16, 17, 18, 19]],\n",
       "\n",
       "        [[ 4,  5,  6,  7],\n",
       "         [20, 21, 22, 23]],\n",
       "\n",
       "        [[ 8,  9, 10, 11],\n",
       "         [24, 25, 26, 27]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [28, 29, 30, 31]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.permute(1,0,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    x = x.view(4,8)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3, 16, 17, 18, 19],\n",
       "        [ 4,  5,  6,  7, 20, 21, 22, 23],\n",
       "        [ 8,  9, 10, 11, 24, 25, 26, 27],\n",
       "        [12, 13, 14, 15, 28, 29, 30, 31]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.contiguous().view(4,8)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_x: tensor([[ 0.3367,  0.1288,  0.2345],\n",
      "        [ 0.2303, -1.1229, -0.1863],\n",
      "        [ 2.2082, -0.6380,  0.4617]])\n",
      "W_y: tensor([[ 0.2674,  0.5349,  0.8094],\n",
      "        [ 1.1103, -1.6898, -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172]])\n",
      "l: 1.3094227313995361\n",
      "Gradient of W_x (manual): tensor(4.9995)\n",
      "Gradient of W_y (manual): tensor(-0.8519)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义常量 x 和 y\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=False)  # 定值\n",
    "y = torch.tensor([0.5, -1.0, 2.0], requires_grad=False)\n",
    "\n",
    "# 初始化 W_x 和 W_y，手动创建梯度张量\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "W_x = torch.randn(3,3, requires_grad=False)\n",
    "W_y = torch.randn(3,3, requires_grad=False) \n",
    "print(\"W_x:\", W_x)\n",
    "print(\"W_y:\", W_y)\n",
    "\n",
    "# 定义中间变量 z = W_x * x + W_y * y\n",
    "z = torch.mm(W_x,x) + torch.mm(W_y * y)\n",
    "\n",
    "# 定义激活函数 tanh(z)\n",
    "tanh_z = torch.tanh(z)\n",
    "\n",
    "# 定义目标函数 l = sum(tanh(z))\n",
    "l = tanh_z.sum()\n",
    "\n",
    "# 手动计算 dl/dz\n",
    "grad_l = torch.tensor(1.0, requires_grad=False)\n",
    "dl_dz = grad_l.expand_as(tanh_z) \n",
    "# 因为 l = sum(tanh(z))，所以对每个 tanh_z 的分量 dl/dtanh_z = 1 \n",
    "\n",
    "# 计算 dz/dW_x 和 dz/dW_y\n",
    "dz_dWx = x  # 因为 z = W_x * x + W_y * y，dz/dW_x = x\n",
    "dz_dWy = y  # dz/dW_y = y\n",
    "\n",
    "# 根据链式法则计算 dl/dW_x 和 dl/dW_y\n",
    "# tanh'(z) = 1 - tanh(z)^2\n",
    "# dl/dW_x = dl/dz * dtanh(z)/dz * dz/dW_x\n",
    "# dl/dW_y = dl/dz * dtanh(z)/dz * dz/dW_y\n",
    "dtanh_dz = 1 - tanh_z**2\n",
    "dl_dWx = dl_dz * dtanh_dz * dz_dWx\n",
    "dl_dWy = dl_dz * dtanh_dz * dz_dWy\n",
    "\n",
    "# 打印结果\n",
    "print(\"l:\", l.item())  # 标量输出\n",
    "print(\"Gradient of W_x (manual):\", dl_dWx.sum())  # dl/dW_x\n",
    "print(\"Gradient of W_y (manual):\", dl_dWy.sum())  # dl/dW_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_x: tensor([[ 0.3367,  0.1288,  0.2345],\n",
      "        [ 0.2303, -1.1229, -0.1863],\n",
      "        [ 2.2082, -0.6380,  0.4617]], requires_grad=True)\n",
      "W_y: tensor([[ 0.2674,  0.5349,  0.8094],\n",
      "        [ 1.1103, -1.6898, -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172]], requires_grad=True)\n",
      "l: 1.3094227313995361\n",
      "Gradient of W_x (manual): tensor(4.9995)\n",
      "Gradient of W_y (manual): tensor(-0.8519)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义常量 x 和 y\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=False)  # 定值\n",
    "y = torch.tensor([0.5, -1.0, 2.0], requires_grad=False)\n",
    "\n",
    "# 初始化 W_x 和 W_y，手动创建梯度张量\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "W_x = torch.randn(3,3, requires_grad=True)\n",
    "W_y = torch.randn(3,3, requires_grad=True) \n",
    "print(\"W_x:\", W_x)\n",
    "print(\"W_y:\", W_y)\n",
    "\n",
    "# 定义中间变量 z = W_x * x + W_y * y\n",
    "# 定义激活函数 tanh(z)\n",
    "# 定义目标函数 l = sum(tanh(z))\n",
    "z = W_x * x + W_y * y\n",
    "tanh_z = torch.tanh(z)\n",
    "l = tanh_z.sum()\n",
    "\n",
    "l.backward()\n",
    "# 打印结果\n",
    "print(\"l:\", l.item())  # 标量输出\n",
    "print(\"Gradient of W_x (manual):\", W_x._grad.sum())  # dl/dW_x\n",
    "print(\"Gradient of W_y (manual):\", W_y._grad.sum())  # dl/dW_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
